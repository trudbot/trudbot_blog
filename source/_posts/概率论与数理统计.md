---
title: 概率论与数理统计
mathjax: true
tags:
  - 概率论
categories: 
  - 数学
  - 概率论
abbrlink: 6768
date: 2023-03-01 16:49:12
---
《概率论与数理统计》课程的知识点整理。

[TOC]

<!--more-->

## 样本空间和概率

### 集合论描述的样本空间和随机事件

#### 样本空间与随机事件

* **样本点：**随机试验的一种可能的结果， 用$\omega$表示。

* **样本空间：** 一个随机试验所有的样本点的集合， 用$\Omega$表示。

* **随机事件：**样本空间$\Omega$的一个子集叫做随机事件， 简称事件， 常用大写字母$A、B、C..$表示。

如"掷一次骰子， 观察出现的点数"这个随机试验中， 1、2、3、4、5、6都是样本点， 而样本空间为$\{1, 2, 3, 4, 5, 6\}$

设事件A:  掷出奇数点。 则A包含了1, 3, 5这三个样本点， $A = \{1, 3, 5\}$

#### 事件的关系(集合的运算)

* **A的逆事件**： $\overline{A}$, A不发生

* **A是B的子事件**： $A \subset B$, A发生一定导致B发生
* **A和B的和事件**:  $A \cup B$， A或B发生
  * **多个事件的和事件**: $\bigcup\limits^{n}_{i=1}A_i$,  n个事件中至少一个发生
* **A和B的积事件**： $A \cap B\  or \  AB$， A和B同时发生
  * **多个事件的积事件**: $\bigcap\limits_{i=1}^{n}A_i$, n个事件同时发生
* **A和B的差事件**： $A - B$, A发生而B不发生
* **A和B是互斥事件**:$A\cap B = \varnothing$ ， A和B不能同时发生
* **A和B是对立事件**： $A \cap B = \varnothing\  \And \ A\cup B = \Omega$， A、B不同时发生， 但必有一个发生

#### 事件的运算

* 交换律
* 结合律
* 分配律
* **德摩根定理**： 
  * $\overline{\bigcap\limits^n_{i=1}A_i} = \bigcup\limits^n_{i=1}\overline{A_i}$
  * $\overline{\bigcup\limits^n_{i=1}A_i} = \bigcap\limits^n_{i=1}\overline{A_i}$

### 概率与概率模型

#### 概率公理

用$P(A)$表示事件A的概率

* 非负性： $P(A) \ge 0$
* 可加性： 若A和B是互斥事件， 则$P(A\cup B) = P(A) + P(B)$
* 归一化： $P(\Omega) = 1$

#### 概率的常用性质

* $P(A) = 1 - P(\overline{A})$
* **减法公式**: $P(A - B) = P(A) - P(AB)$
* **广义加法公式**: $P(A\cup B) = P(A) + P(B) - P(AB)$

#### 古典概型（离散模型）

若样本空间由有限个样本点组成， 且由每个样本点组成的事件(基本事件)的概率相等， 

有
$$
P(A) = \dfrac{A事件包含的样本点个数}{样本点总数}
$$
如上面的“掷骰子试验”就是一个古典概型，

事件A"掷出奇数"的概率$P(A) = \frac{3}{6} = \frac12$

#### 几何概型（连续模型）

若试验的样本空间是一个连续集合,其相应的概率律与离散情况有很大的差别.在离散情况下,用基本事件的概率就可以确定概率律,但连续情况却不同.

> 罗密欧和朱丽叶约定在某时刻见面,而每个人到达约会地点的时间都会有延迟,延迟时间在0~1小时.第一个到达约会地点的人会在那儿等待15分钟,等了15分钟后,若对方还没有到达约会地点,先到者会离开约会地点.问他们能够相会的概率有多大?

考虑直角坐标系的单位正方形$\Omega = [0, 1] \times [0, 1]$ .正方形中的每个点的两个坐标分别代表他们可能的延迟时间.每个点都可以是他们的延迟时间,而且是等可能的.由于等可能性的特点,我们将 $\Omega$的子集出现的概率定义为这个子集的面积.这个概率律满足三条概率公理.罗密欧和朱丽叶能够相会的事件可用下图中阴影部分表示.它的概率等于7/16.

![](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230301180156136.png)

### 条件概率

在事件$B$已发生的基础上, 求事件$A$发生的概率. 这个概率就叫做B发生之下A的条件概率, 记为$P(A|B)$.

条件概率定义:
$$
P(A|B) = \dfrac{P(AB)}{P(B)}
$$

### 全概率公式和贝叶斯公式

**全概率公式**

若事件$A_1, A_2, ..., A_n$构成样本空间$\Omega$的一组划分, 则对于任意事件$B$, 有:
$$
P(B) = \sum_{i=1}^{n}P(A_i \cap B) = \sum_{i=1}^{n}P(B|A_i)P(A_i)
$$
全概率定理是与著名的贝叶斯准则联系在一起的.贝叶斯准则将形如$P(A|B)$的条件概
率与形如$P(B|A)$的条件概率联系起来.

**贝叶斯公式**

若事件$A_1, A_2, ..., A_n$构成样本空间$\Omega$的一组划分, 且对于所有每一个$i$, 满足$P(i) > 0$, 则对于任意满足$P(B) > 0$的事件B, 有
$$
\begin{array}{lcl}
P(A_i | B) & =  &\dfrac{P(A_iB)}{P(B)}\\
& = & \dfrac{P(B|A_i)P(A_i)}{\sum\limits_{j=1}^{n}P(B|A_j)P(A_j)}
\end{array}
$$

> 根据以往的记录，某种诊断肝炎的试验有如下效果：对肝炎病人的试验呈阳性的概率为0.95；非肝炎病人的试验呈阴性的概率为0.95．对自然人群进行普查的结果为：有千分之五的人患有肝炎．现有某人做此试验结果为阳性，问此人患有肝炎的概率为多少？
>
> 解:
>
> 设事件$A$:  患有肝炎, 事件$B$: 试验结果为阳性.
>
> 由题中信息可知, $P(B|A) = 0.95$, $P(\overline{B}|\overline{A}) = 0.95$, $P(A) = 0.005$
>
> 要求的也就是$P(A|B)$, $A$与$\overline{A}$构成了一组划分, 由贝叶斯公式
> $$
> P(A|B) = \dfrac{P(A)P(B|A)}{P(B|A)P(A) + P(B|\overline{A})P(\overline{A})} = \dfrac{0.005 \times 0.95}{0.005\times 0.95 + (1-0.005)\times (1-0.95)} \approx 0.0872
> $$
> 

### 独立性

对于事件$A、B$， 若满足$P(AB) = P(A)P(B)$, 则称$A、B$相互独立。

当满足$P(A) > 0$ 且$P(B) > 0$时， $A和B相互独立\iff A和B不互斥$， $A和B互斥\iff A和B不相互独立$。

**多个事件的独立性**

若从n个事件$\{A_1, A_2, ..., A_n\}$中任取m$(m \ge 2)$个事件$\{A_{i1}, A_{i2}, ..., A_{im}\}$， 都有$P(A_{i1}A_{i2}...A_{im}) = P(A_{i1})P(A_{i2})...P(A_{im})$， 则称这n个事件是相互独立的。

如$A, B, C$若相互独立， 当且仅当:
$$
\begin{array}{lcl}
P(ABC) = P(A)P(B)P(C) \\
P(AB) = P(A)P(B) \\
P(AC) = P(A)P(C) \\
P(BC) = P(B)P(C)
\end{array}
$$

**若$A, B$相互独立， 则$A和\overline{B}$、$\overline{A}和B$、$\overline{A}和\overline{B}$都相互独立。**

### 伯努利概型

设试验$E$只有两种可能的结果$A和\overline{A}$, , 将$E$独立地重复进行n次,这称这一系列重复的独立试验为n重伯努利试验或n重伯努利概型.

定理: 设$P(A) = p, P(\overline{A}) = 1 - p$, 则n次试验中， 事件A恰好发生$k$次的概率为:
$$
P_n(k) = C_{n}^{k}p^k(1-p)^{n - k}, \ (k = 0, 1, 2, ..., n)
$$


## 离散随机变量

### 随机变量

在实际中， 随机试验的每一个样本点往往可以用数值来表示， 样本点和数值的映射被称为随机变量， 记为$X$。从数学上讲, 随机变量
是试验结果的实值函数， 也就是说， 对于每一个样本点$\omega$， 都有数值$X(\omega)$与之对应.

举个例子， 连续抛掷一枚硬币共5次,在这个试验中正面出现的次数是一个随机变量$X$, $X$的取值范围为$1, 2, 3, 4, 5$.

然而作为试验结果的长度为5的正面和反面的序列却不能作为随机变量,因为它对于一个试验结果没有给出一个明显的数值.

### 离散随机变量

若一个随机变量的值域(随机变量的取值范围)为一个有限集合或最多为可数无限集合,则称这个随机变量为离散的.

离散随机变量有如下特点：

* 离散随机变量是试验结果的一个实值函数,但是它的取值范围只能是有限多个值或可数无限多个值;
* 一个离散随机变量有一个分布列,它对于随机变量的每一个取值, 给出一个概率;
* 离散随机变量的函数也是一个离散随机变量, 它的分布列可以从原随机变量的分布列得到.

### 分布列

使用离散随机变量可以方便的描述基本事件， 基本事件$\{\omega\}$等同于$\{X = X(\omega)\}$,  设$x = X(\omega)$， 则随机变量$X$等于x的概率记为:$P_X(x)$.

离散随机变量取每个值时的概率是随机变量的最重要的特征, 描述这一特征的函数或图表就是其分布列。

如，设$X$为将硬币独立地抛两次的试验中， 正面向上的次数。

则$X$的分布列为
$$
\begin{array}{c|ccc}
x & 0 & 1 & 2 \\ \hline
P_X(x) & \frac14 & \frac12 & \frac14
\end{array}
$$
对于分布列， 有$\sum\limits_xP_X(x) = 1$

#### 01分布

当离散随机变量$X$只有两种可能的取值时， 我们称$X$是01分布， 或$X$是伯努利随机变量。
$$
\begin{array}{c|ccc}
x & 0 & 1\\ \hline
P_X(x) & 1-p & p
\end{array}
$$

#### 二项分布

在伯努利概型中， 设$X$为n次试验中A发生的次数($P(A) = p$)， 则有分布列$P_X(x) = C_n^xp^x(1-p)^{n-x}$, 称$X$是参数为$(n, p)$的二项分布， 记作$X \sim B(n, p)$。

#### 几何分布

在连续抛掷硬币的试验中, 每次抛掷, 正面出现的概率为 p ,反面出现的概率为 1-p, 而且各次抛掷是相互独立的.令 X 为连续地抛掷一枚硬币, 直到第一次出现正面所需要抛掷的次数. X 就称为几何随机变量.前 k-1 次抛掷的结果为反面向上, 第 k 次抛掷的结果为正面向上的概率为$(1-p)^{k-1}p$ . 因此 X 的分布列为$P_X(k) = (1-p)^{k-1}p, \ k = 1, 2, 3, ..$

![image-20230303212728760](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230303212728760.png)

#### 泊松分布

若随机变量$X$的分布列满足:
$$
P_X(k) = \dfrac{\lambda^k}{k!}e^{-\lambda}, \ k = 0, 1, 2, 3, ...
$$
则称$X$服从参数$\lambda$的泊松分布。

---



##### 高数二知识补充
> 高数二补充
>
> > $\sum\limits_0^{\infty}\dfrac{\lambda^k}{k!} = e^\lambda$

![image-20230303213941942](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230303213941942.png)

## 连续随机变量

### 分布函数

设$X$为一随机变量， x是任意实数， 则X的分布函数$F_X(x) = P_X(X \leq x), -\infty \leq x \leq +\infty$, 分布函数简写为$CDF$

### 密度函数

设随机变量$X$分布函数为$F_X(x)$, 若非负函数$f(x)$满足$F_X(x) = \int_{-\infty}^x f(x)\, dx$, 则$f(x)$被称为$X$的密度函数, $X$被称为连续型随机变量。

密度函数简写为$PDF$

**密度函数的性质**

* 非负性， $f(x) \geq 0$
* 归一性， $\int^{+\infty}_{-\infty}f(x) dx = 1$
* 对于任意实数$a, b(a < b)$, 有$P(a < X \leq b) = F_X(b) - F_X(a)= \int_a^bf(x)dx$
* $f(x)$的大小并不代表$X$取x的概率, 但$f(x)$越大, $X$在x附近取值的概率也就越大
* 若$f(x)$在x处连续， 则有$f(x) = \dfrac{dF_X}{dx}$ 

### 连续随机变量的性质

对于连续型随机变量$X$, 有

* $X$的分布函数$F_X(x)$连续
* $P(X = x) = \int_x^xf(x)dx = 0$, 所以对于连续型随机变量, 其在某一点上的取值概率没有意义, 我们更多关心其在区间内的取值概率.

### 正态分布

当一个随机变量X被称为正态分布时， 它的概率密度有如下格式：
$$
f(x) = \dfrac{1}{\sqrt{2\pi\sigma}}e^{-\dfrac{(x-\mu)^2}{2\sigma^2}}
$$
随机变量X服从随机分布式, 简写为$X\sim N(\mu, \sigma^2)$

![image-20230316082220452](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230316082220452.png)

**正态分布特点**

* 正态分布曲线呈钟形, 且关于$x = \mu$对称, 再$x = u$处达到最大值
* $x = \mu \pm \sigma$为曲线的拐点
* $\lim\limits_{x\rightarrow \infty}f(x) = 0$, 所以x轴为正态分布的水平渐近线
* 正态分布的均值为$\mu$, 方差为$\sigma^2$
* 线性变换后随机变量的正态性保持不变, 如随机变量$Y = aX + b$, 均值为$a\mu + b$, 方差为$a^2\sigma^2$

**标准正态分布**

当$\mu = 0, \sigma = 1$时, 称X满足标准正态分布, 记为$X\sim N(0, 1)$

![image-20230316085903256](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230316085903256.png)

**标准正态分布的性质**

若随机变量$X \sim N(0, 1)$, 则

* $F_X(-x) = 1 - F_X(x)$(利用标准正态分布关于y轴对称的特点)
* 如何正态分布都可以通过线性变换转换为标准正态分布. 设$X$为任意一正态随机变量, 令$Y = \dfrac{X - \mu}{\sigma}$, $Y$显然为正态随机变量.

### 二维随机变量(多个随机变量的联合分布)

**二维随机变量的分布函数**

定义$F(x, y) = P(X \leq x, Y \leq y)$为二维随机变量$(X, Y)$的分布函数。

![image-20230423170030246](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230423170030246.png)

**二维随机变量分布函数的性质**

* $0 \leq F(X, Y) \leq 1$
* $F(-\infty, -\infty) = 0, F(+\infty, +\infty) = 1$
* 对于固定的值$x, y$， 有$F(-\infty, y) = 0, F(x, -\infty) = 0$

#### 和分布的卷积公式

设随机变量$X, Y$相互独立， 密度函数为$f_X(x), f_Y(y)$, 设$Z = X + Y $则
$$
f_Z(z) = \int^{+\infty}_{-\infty}f_X(x)f_Y(z-y)dx
$$


### 边缘分布

#### 定义

二维随机变量$(X, Y)$通常使用分布函数$F(x, y)$来描述其本质特征， 而其中单个随机变量$X或Y$， 也可以用相应的分布函数$F_X(x)或F_Y(y)$单独描述。由单个$X$或$Y$确定的分布就称为边缘分布。

#### 公式

对于二维离散型随机变量$(X, Y)$， $P(X=x_i) = \sum\limits_1^nP(x_i, y_i)$

---

对于二维连续型随机变量$(X, Y)$。

$F_X(x) = P(X \leq x) = P\{X\leq x, Y < +\infty\} = F(x, +\infty)$

所以, 关于$X$的边缘分布函数为

$F_X(x) = \int_{-\infty}^xdx\int^{+\infty}_{-\infty}f(x, y)dy$

关于$X$的边缘密度函数为

$f_X(x) = \dfrac{d}{dx}F_X(x) = \int^{+\infty}_{-\infty}f(x, y)dy$

## 数字特征

### 数学期望

#### 定义

**离散型**
$$
EX = \sum\limits_{1}^{\infty}x_ip_i
$$
**连续型**
$$
EX = \int_{-\infty}^{+\infty}xf(x)dx
$$

#### 已知X的分布， 求$E[g(X)]$

**离散型**
$$
EX = \sum\limits_{1}^{\infty}g(x_i)p_i
$$
**连续型**
$$
EX = \int_{-\infty}^{+\infty}g(x)f(x)dx \\
E[g(X, Y)] = \int_{-\infty}^{+\infty}{\int_{-\infty}^{+\infty}g(x, y)f(x, y)dx}dy
$$

#### 性质

* 对于k为常数, $E(kX) = kE(X)$
* 对任意随机变量X, Y, 有$E(X + Y) = EX + EY$
* 对于相互独立的两个随机变量X, Y, 有$E(XY) = E(X)E(Y)$

#### 常见分布的数学期望

![image-20230425135438938](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230425135438938.png)



### 方差

#### 定义

$$
D(X) = E[X - E(X)]^2 \\
or\\
D(X) = E(X^2) - E(X)^2
$$

$D(X)$是刻画X取值分散程度的一个量.

若X的取值比较集中,则方差D(X)较小, E(X)作为随机变量的代表性好；

若X的取值比较分散,则方差D(X)较大, E(X)作为随机变量的代表性差.

**标准差**

称$\sqrt{D(X)}$为X的标准差.

#### 性质

* 若c为常数, 则$D(c) = 0$
* 若k为常数, 则$D(kX) = k^2 D(X)$
* 对于任意随机变量$X, Y$, 有$D(X\pm Y) = D(X) + D(Y) \pm 2E\{[X - E(X)][Y-E(Y)]\}$
* 对于相互独立的两个随机变量X, Y, 有$D(X\pm Y) = D(X) + D(Y)$

#### 常见分布的方差

![image-20230425140516258](https://raw.githubusercontent.com/trudbot/trudbot_images/main/md_img/image-20230425140516258.png)



### 大数定律

#### 切比雪夫不等式

设随机变量$X$的数学期望$E(X)$和方差$D(X)$都存在, 则$\forall \varepsilon > 0$, 有
$$
P\{|X - EX| \geq \varepsilon\} \leq \dfrac{D(X)}{\varepsilon^2} \\or\\
P\{|X - EX| < \varepsilon\} \geq 1 - \dfrac{D(X)}{\varepsilon^2}
$$

## 参数估计与假设检验

### 总体和样本

**总体**： 统计问题研究对象的全体

**个体**：总体中的每一个成员

---

#### 样本

设$X_1,X_2,..., X_n$是取自总体$X$的的一组样本, 且满足

* $X_1, X_2, ..., X_n$相互独立
* $X_1, X_2, ..., X_n$与$X$同分布

则称$X_1, X_2, ..., X_n$是容量为n的简单随机样本(简称样本).

样本观测值： 对样本的观察值, 记作$x_1, x_2, ..., x_n$

### 统计量与样本矩

